package com.playerid.app.ml

import android.content.Context
import android.graphics.Bitmap
import android.graphics.RectF
import android.util.Log
import androidx.camera.core.ImageProxy
import com.playerid.app.data.DetectedPlayer
import kotlinx.coroutines.*
// TEMPORARILY DISABLED FOR DEBUGGING - TensorFlow Lite dependencies removed
// import org.tensorflow.lite.Interpreter
import java.io.FileInputStream
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.nio.channels.FileChannel

/**
 * üöÄ AutoML Jersey Detector
 * Integrates trained AutoML Vision Edge model with existing PlayerID system
 */
class AutoMLJerseyDetector(private val context: Context) {
    
    private var interpreter: Interpreter? = null
    private var isModelLoaded = false
    
    companion object {
        private const val TAG = "AutoMLJerseyDetector"
        private const val MODEL_FILE = "jersey_detector_v1.tflite"
        private const val INPUT_SIZE = 320
        private const val CONFIDENCE_THRESHOLD = 0.8f
        
        // Based on our training dataset: jersey numbers we trained on
        private val JERSEY_CLASSES = mapOf(
            0 to "0",   // 1,866 images
            1 to "1",   // 441 images  
            2 to "2",   // Various counts
            3 to "5",
            4 to "6", 
            5 to "7",
            6 to "8",
            7 to "9",
            8 to "10"   // 598 images
            // Add more as needed based on training results
        )
    }
    
    init {
        loadModel()
    }
    
    /**
     * üì• Load the trained AutoML model
     */
    private fun loadModel() {
        try {
            val assetManager = context.assets
            val modelInputStream = assetManager.open(MODEL_FILE)
            val modelBuffer = ByteBuffer.allocateDirect(modelInputStream.available())
            
            modelInputStream.use { input ->
                val channel = (input as FileInputStream).channel
                channel.read(modelBuffer)
            }
            modelBuffer.rewind()
            
            val options = Interpreter.Options().apply {
                setNumThreads(4) // Optimize for mobile performance
                setUseNNAPI(true) // Use Android Neural Networks API if available
            }
            
            interpreter = Interpreter(modelBuffer, options)
            isModelLoaded = true
            
            Log.i(TAG, "‚úÖ AutoML jersey detection model loaded successfully")
            Log.i(TAG, "üìä Input shape: ${interpreter!!.getInputTensor(0).shape().contentToString()}")
            Log.i(TAG, "üìä Output shape: ${interpreter!!.getOutputTensor(0).shape().contentToString()}")
            
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Failed to load AutoML model: ${e.message}")
            isModelLoaded = false
        }
    }
    
    /**
     * üéØ Detect jersey numbers using AutoML model
     */
    suspend fun detectJerseyNumbers(bitmap: Bitmap): List<DetectedPlayer> = withContext(Dispatchers.Default) {
        if (!isModelLoaded) {
            Log.w(TAG, "‚ö†Ô∏è AutoML model not loaded")
            return@withContext emptyList()
        }
        
        try {
            // Preprocess image
            val inputBuffer = preprocessImage(bitmap)
            
            // Prepare output buffer based on AutoML format
            // AutoML Vision classification typically returns class probabilities
            val outputBuffer = Array(1) { FloatArray(JERSEY_CLASSES.size) }
            
            // Run inference
            interpreter!!.run(inputBuffer, outputBuffer)
            
            // Process results
            val detections = processClassificationResults(outputBuffer[0], bitmap)
            
            Log.d(TAG, "üéØ AutoML detected ${detections.size} jersey numbers")
            return@withContext detections
            
        } catch (e: Exception) {
            Log.e(TAG, "üí• AutoML detection failed: ${e.message}")
            return@withContext emptyList()
        }
    }
    
    /**
     * üñºÔ∏è Preprocess image for AutoML model input
     */
    private fun preprocessImage(bitmap: Bitmap): ByteBuffer {
        // Resize bitmap to model input size
        val resizedBitmap = Bitmap.createScaledBitmap(bitmap, INPUT_SIZE, INPUT_SIZE, true)
        
        // Create input buffer
        val inputBuffer = ByteBuffer.allocateDirect(4 * INPUT_SIZE * INPUT_SIZE * 3)
        inputBuffer.order(ByteOrder.nativeOrder())
        
        // Convert bitmap to normalized float values
        val pixels = IntArray(INPUT_SIZE * INPUT_SIZE)
        resizedBitmap.getPixels(pixels, 0, INPUT_SIZE, 0, 0, INPUT_SIZE, INPUT_SIZE)
        
        for (pixel in pixels) {
            // Normalize RGB values to [0, 1] range
            val r = ((pixel shr 16) and 0xFF) / 255.0f
            val g = ((pixel shr 8) and 0xFF) / 255.0f  
            val b = (pixel and 0xFF) / 255.0f
            
            inputBuffer.putFloat(r)
            inputBuffer.putFloat(g)
            inputBuffer.putFloat(b)
        }
        
        return inputBuffer
    }
    
    /**
     * üìä Process AutoML classification results
     */
    private fun processClassificationResults(probabilities: FloatArray, originalBitmap: Bitmap): List<DetectedPlayer> {
        val detections = mutableListOf<DetectedPlayer>()
        
        // Find the class with highest confidence above threshold
        val maxIndex = probabilities.indices.maxByOrNull { probabilities[it] } ?: return emptyList()
        val maxConfidence = probabilities[maxIndex]
        
        if (maxConfidence >= CONFIDENCE_THRESHOLD) {
            val jerseyNumber = JERSEY_CLASSES[maxIndex]
            
            if (jerseyNumber != null) {
                // For classification models, we don't have precise bounding boxes
                // Create a centered detection area (can be improved with object detection model later)
                val centerX = originalBitmap.width / 2f
                val centerY = originalBitmap.height / 2f
                val width = originalBitmap.width * 0.3f  // Assume jersey is ~30% of image width
                val height = originalBitmap.height * 0.4f // Assume jersey is ~40% of image height
                
                val boundingBox = RectF(
                    centerX - width / 2,
                    centerY - height / 2,
                    centerX + width / 2,
                    centerY + height / 2
                )
                
                val detection = DetectedPlayer(
                    number = jerseyNumber.toIntOrNull() ?: 0,
                    confidence = maxConfidence,
                    boundingBox = boundingBox,
                    player = null // Will be looked up later
                )
                
                detections.add(detection)
                Log.d(TAG, "‚úÖ AutoML detected jersey #$jerseyNumber with ${(maxConfidence * 100).toInt()}% confidence")
            }
        } else {
            Log.d(TAG, "üîç AutoML confidence too low: ${(maxConfidence * 100).toInt()}% < ${(CONFIDENCE_THRESHOLD * 100).toInt()}%")
        }
        
        return detections
    }
    
    /**
     * üìä Get model status information
     */
    fun getModelInfo(): ModelInfo {
        return ModelInfo(
            isLoaded = isModelLoaded,
            modelName = "AutoML Jersey Detector v1",
            inputSize = INPUT_SIZE,
            confidenceThreshold = CONFIDENCE_THRESHOLD,
            supportedClasses = JERSEY_CLASSES.values.toList()
        )
    }
    
    /**
     * üßπ Clean up resources
     */
    fun cleanup() {
        interpreter?.close()
        interpreter = null
        isModelLoaded = false
        Log.d(TAG, "üßπ AutoML detector resources cleaned up")
    }
}

/**
 * üìä Model information data class
 */
data class ModelInfo(
    val isLoaded: Boolean,
    val modelName: String,
    val inputSize: Int,
    val confidenceThreshold: Float,
    val supportedClasses: List<String>
)